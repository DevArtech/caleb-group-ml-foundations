{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logisitic Regression\n",
    "Adam Haile - 2/20/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run if you don't have the packages installed\n",
    "# %pip install numpy matplotlib scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out the IRIS dataset again, like we did in Linear Regression. This time we want to determine the type of iris we have from our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  # Features\n",
    "y = iris.target  # Target labels (0, 1, 2 corresponding to the 3 iris species)\n",
    "\n",
    "# Let's see what we have here\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see from our data that this time we are working with 4 features, and 3 different classes. This is fine, as SKLearn supports the ability to train a logistic regression model that can perform multi-class predicting. \n",
    "\n",
    "*(Under the hood, it's essentially training multiple logistic regression models that each learn a specific class. They then learn to predict \"is it my class, or some other class\".)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize features (important for logistic regression, will help us with reaching convergence)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression model\n",
    "# ovr means one-vs-rest, lbfgs is a solver that uses an iterative approach to find the best fit\n",
    "clf = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=200)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate our Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "disp = ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test, display_labels=iris.target_names, cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's interpret these results.\n",
    "\n",
    "First thing we get is the general model accuracy. We get an accuracy of 0.9 which is pretty good!\n",
    "\n",
    "Next we get our classification report, this is a breakdown of more nuanced ways to evaluate the model. Let's break some of these down.\n",
    "1. Accuracy: $\\frac{(TP + TN)}{TP + TN + FP + TN}$. Accuracy is a metric which tells us proportion of correctly classified datapoints out of all datapoints in the dataset. It works well when datasets are balanced and all categories for false classification have similar consequences (predicting a False Positive is no worse than predicting a False Negative, vise versa.)\n",
    "2. Precision: $\\frac{TP}{TP + FP}$. Measures how many of the positive cases are actually positive. This is good for when the consquenses for making a false positive are more costly. Ex: Spam detection, where marking an important email as spam is bad. Does not factor in the negative case at all.\n",
    "3. Recall: $\\frac{TP}{TP + FN}$. Measures how many positive cases were correctly identified. Better for when false negatives are more costly. Ex: Medical diagnosis where missing a disease can be deadly. \n",
    "4. F1 Score: $2 \\times \\frac{Precision \\times Recall}{Precision + Recall}$. Balances both precision and recall. Prevents a model from becoming too conservative (High precision, low recall) or aggressive (High recall, low precision).\n",
    "\n",
    "We can see that across the board, the model gets 90% on Accuracy, Precision, Recall, and F1 score. This is good! It means our model is generalizing well to the unseen data and is decently performant (getting a 90% or greater on models in a real-world usecase is a pretty rare thing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing our own Logistic Regression\n",
    "\n",
    "We've now seen how to use logistic regression, lets make it from scratch! As last time, I am going to leave some segments for you to do instead of just executing code cells down a notebook >:)\n",
    "\n",
    "We'll use the same data as before, so no need to import any new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.c_[...((X_train.shape[0], 1)), X_train]  # TODO: Add ones to first column for our bias term\n",
    "X_test = np.c_[...((X_test.shape[0], 1)), X_test]  # TODO: Add ones to first column for our bias term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<details>\n",
    "<summary>Click here to reveal the answer</summary>\n",
    "\n",
    "<pre><code>\n",
    "X_train = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "X_test = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "</code></pre>\n",
    "\n",
    "</details>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define some helper functions. Refer back to the slides if you want some help on the structure of these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"Compute the sigmoid function.\"\"\"\n",
    "    return ... # TODO: Implement the sigmoid function\n",
    "\n",
    "def compute_loss(y, y_pred):\n",
    "    \"\"\"Compute binary cross-entropy loss.\"\"\"\n",
    "    # Some help with what this function should look like: https://koshurai.medium.com/understanding-log-loss-a-comprehensive-guide-with-code-examples-c79cf5411426\n",
    "    m = 1e-9\n",
    "    return ... # TODO: Implement the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<details>\n",
    "<summary>Click here to reveal the answer</summary>\n",
    "\n",
    "<pre><code>\n",
    "def sigmoid(z):\n",
    "    \"\"\"Compute the sigmoid function.\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def compute_loss(y, y_pred):\n",
    "    \"\"\"Compute binary cross-entropy loss.\"\"\"\n",
    "    m = 1e-9\n",
    "    return -np.mean(y * np.log(y_pred + m) + (1 - y) * np.log(1 - y_pred + m))\n",
    "</code></pre>\n",
    "\n",
    "</details>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll implement gradient descent for you this time, but let's break down what it's doing so you can do it the next time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, lr=0.1, epochs=1000):\n",
    "    \"\"\"Train logistic regression using gradient descent.\"\"\"\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros(n)  # Initialize weights\n",
    "    \n",
    "    loss_history = []\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        z = X @ theta  # Linear combination\n",
    "        y_pred = sigmoid(z)  # Apply sigmoid\n",
    "        \n",
    "        gradient = (1 / m) * (X.T @ (y_pred - y))  # Compute gradient\n",
    "        theta -= lr * gradient  # Update weights\n",
    "        \n",
    "        loss = compute_loss(y, y_pred)\n",
    "        loss_history.append(loss)\n",
    "    \n",
    "    return theta, loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't taken Calc 3 yet, think of Gradient Descent as an optimization algorithm that helps find a local minimum of a function. Imagine you have a ball at the top of a valley. Instead of just rolling freely, at each step, you check the slope (gradient) of the valley at your current position and take a small step downhill. The steepness tells you how much to move and in which direction.\n",
    "\n",
    "In machine learning, this means adjusting the modelâ€™s parameters (weights) iteratively to minimize a loss function. The gradient of the loss function tells us how to update the weights: the larger the gradient, the bigger the step. Over multiple iterations, the weights gradually move toward a minimum where the loss is minimized\n",
    "\n",
    "Let's break this down.\n",
    "\n",
    "```\n",
    "m, n = X.shape\n",
    "theta = np.zeros(n)\n",
    "\n",
    "loss_history = []\n",
    "```\n",
    "First thing we are doing is initializing our weights and additional terms that we will need to help us compute gradients.\n",
    "\n",
    "```\n",
    "for _ in range(epochs):\n",
    "    z = X @ theta\n",
    "    y_pred = sigmoid(z)\n",
    "```\n",
    "This segment is the start of our iterative loop. On the first part of the loop, we are computing the matrix multiplication between our input (X) and our current weights (theta). This will give us a transformation of our input to our linear model. We are then taking the sigmoid of the linear function to get our predicted values from the input. (In this case, the predictions of our entire training set). \n",
    "\n",
    "```\n",
    "gradient = (1 / m) * (X.T @ (y_pred - y))\n",
    "```\n",
    "Next, we are computing our gradient. This will tell us what direction we need to move our parameters to in order to reach our minimum and in what direction. This will take the matrix multiplcation of our original training input and the error of our prediction (y_pred - y), and multiply it by 1 / the number of features. \n",
    "\n",
    "```\n",
    "theta -= lr * gradient\n",
    "```\n",
    "The theta is our newly updated model parameters. We subtract it because by default, the gradient is computing the uphill maximized option (which we don't want, we want to move down). We also multiply it by a learning rate parameter which will help us prevent undershoot/overshooting our target parameters.\n",
    "\n",
    "```\n",
    "loss = compute_loss(y, y_pred)\n",
    "loss_history.append(loss)\n",
    "```\n",
    "Last thing we do is compute our loss. This allows us to know how well our model's predictions do compared to the actual values. We can store these for evaluation later.\n",
    "\n",
    "Great! So now that we have all that, lets train a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, loss_history = gradient_descent(X_train, y_train, lr=0.1, epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the loss history curve and see how our model did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our model hit a pretty good accuracy point at around 200 epochs and then flatlined at the same parameters/loss for the rest of the epochs. We also see that our loss history went into the **negatives**, which doesn't entirely make sense since we know that log-likelihood should always be **non-negative**. More on this later, for now let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta):\n",
    "    \"\"\"Predict class labels (0 or 1) for input X.\"\"\"\n",
    "    return (...(...) >= ...).astype(int) # TODO: Implement the necessary logic to make predictions\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = predict(X_test, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now check our model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm. Our model did worse, why is that?\n",
    "\n",
    "Well, remember how when we used the SKLearn model before, we specified the \"ovr\" parameter? That is because we were trying to predict against more than 2 classes. Because of this, we need more than 1 logistic regression model in order to make accurate results as logistic regression can only produce outputs against a binary set of classes. Our model is attempting to do the same predictions with only **one** model.\n",
    "\n",
    "Let's do some preprocessing and retrain our model on the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:, :2] # Using only the first two features -- will make visualizing easier later.\n",
    "X = X[y < 2]  # Take only class 0 and 1\n",
    "y = y[y < 2]  # Labels remain 0 and 1\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Add bias term (Intercept) to X\n",
    "X_train = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "X_test = np.c_[np.ones((X_test.shape[0], 1)), X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are just looking at two of our classes in the dataset rather than all 3. We should get a much better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, loss_history = gradient_descent(X_train, y_train, lr=0.1, epochs=1000)\n",
    "\n",
    "# Plot loss curve\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this time we see a better loss graph. Before, our model's loss went into the **negatives**. This is also because out function is operating with more classes than it could predict on (another indicator of the model being unable to fit). This is apart of why understanding your data is important before attempting to use it in a model.\n",
    "\n",
    "Now that we have a corrected model, let's look at our accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = predict(X_test, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Now we are getting an accuracy of 100%! Let's take a look at the data and understand why with this model, that result makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(X, y, theta):\n",
    "    \"\"\"Visualizes the decision boundary for logistic regression.\"\"\"\n",
    "    x_min, x_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    y_min, y_max = X[:, 2].min() - 0.5, X[:, 2].max() + 0.5\n",
    "\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "    grid = np.c_[np.ones((xx.ravel().shape[0], 1)), xx.ravel(), yy.ravel()]\n",
    "    probs = sigmoid(grid @ theta).reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx, yy, probs, levels=[0, 0.5, 1], cmap=\"coolwarm\", alpha=0.2)\n",
    "    plt.scatter(X[:, 1], X[:, 2], c=y, edgecolors=\"k\", cmap=\"coolwarm\")\n",
    "    plt.xlabel(\"Feature 1 (Standardized)\")\n",
    "    plt.ylabel(\"Feature 2 (Standardized)\")\n",
    "    plt.title(\"Logistic Regression Decision Boundary\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot decision boundary with test data points\n",
    "X_combined = np.vstack((X_train, X_test))\n",
    "y_combined = np.concatenate((y_train, y_test))\n",
    "plot_decision_boundary(X_combined, y_combined, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, looking at our scatter plot, we can see there is a distinct separation between our features. Because of this completely linear separation, we can form a decision boundary that entirely separates these two classes, making logistic regression a great choice for this problem!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
